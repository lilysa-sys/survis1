@article{Adaptive Partition Testing,
  abstract = { Random testing and partition testing are two major families of software testing techniques. They have been compared both theoretically and empirically in numerous studies for decades, and it has been widely acknowledged that they have their own advantages and disadvantages and that their innate characteristics are fairly complementary to each other. Some work has been conducted to develop advanced testing techniques through the integration of random testing and partition testing, attempting to preserve the advantages of both while minimizing their disadvantages. In this paper, we propose a new testing approach, adaptive partition testing, where test cases are randomly selected from some partition whose probability of being selected is adaptively adjusted along the testing process. We particularly develop two algorithms, Markov-chain based adaptive partition testing and reward-punishment based adaptive partition testing, to implement the proposed approach. The former algorithm makes use of Markov matrix to dynamically adjust the probability of a partition to be selected for conducting tests; while the latter is based on a reward and punishment mechanism. We conduct empirical studies to evaluate the performance of the proposed algorithms using ten faulty versions of three large-scale open source programs. Our experimental results show that, compared with two baseline techniques, namely random partition testing (RPT) and dynamic random testing (DRT), our algorithms deliver higher fault-detection effectiveness with lower test case selection overhead. It is demonstrated that the proposed adaptive partition testing is an effective testing approach, taking advantages of both random testing and partition testing.},
  author = {Chang-Ai Sun, Hepeng Dai, Huai Liu,Tsong Yueh Chen, Kai-Yuan Cai},
  doi = {10.1109/TC.2018.2866040},
  journal = {IEEE Transactions on Computers},
  keywords = {Software testing,Markov processes,Probability,Statistical analysis},
  number = {01},
  publisher = {IEEE},
  volume = {68},
  series = {Foundational Theories and Core Mechanisms},
  title = {Adaptive Partition Testing},
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8440117},
  year = {2018}
}
@article{Adaptive Random Testing: The ART of test case diversity,
  abstract = {Random testing is not only a useful testing technique in itself, but also plays a core role in many other testing methods. Hence, any significant improvement to random testing has an impact throughout the software testing community. Recently, Adaptive Random Testing (ART) was proposed as an effective alternative to random testing. This paper presents a synthesis of the most important research results related to ART. In the course of our research and through further reflection, we have realised how the techniques and concepts of ART can be applied in a much broader context, which we present here. We believe such ideas can be applied in a variety of areas of software testing, and even beyond software testing. Amongst these ideas, we particularly note the fundamental role of diversity in test case selection strategies. We hope this paper serves to provoke further discussions and investigations of these ideas.}
  author = {Tsong Yueh Chen, Fei-Ching Kuo , Robert G. Merkel, T.H. Tse},
  doi = {10.1016/j.jss.2009.02.022},
  journal = {Journal of Systems and Software},
  keywords = {Software testingRandom testingAdaptive random testingAdaptive random sequenceFailure-based testingFailure pattern},
  number = {02},
  publisher = {Journal of Systems and Software},
  volume = {83},
  series = {Foundational Theories and Core Mechanisms},
  title = {Adaptive Random Testing: The ART of test case diversity},
  url = {extension://ngbkcglbmlglgldjfcnhaijeecaccgfi/https://pdf.sciencedirectassets.com/271629/1-s2.0-S0164121209X00130/1-s2.0-S0164121209000405/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEKv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQDyk4UcrYZx0QhX6mA3iXYSSMxgxUtmwVZNIG%2BacOrb5wIgSVm3ZbJ843NPeoymqSdxTWJ8gpjmEzVB9oxPJ3RTJUMqswUIVBAFGgwwNTkwMDM1NDY4NjUiDHpZS8zRpxU7HxMMpiqQBXkga3N9bhCTrYr0NeYlbe5mDizI1lBQE8Oa7qKrByY5N8H7sUVIRm8Calw99KRduZeyI6KjCSvbvDpfT933denIgFQJgK2z%2BWmumMykRKFARJkVG5HVObjScUFevPvlLAkLIu%2F%2Ffpuz3D86DSzqzW5WmKqVS%2FNTiAkFlMfZ14pBoGmb69crDJFN3iaqu40y%2B7jlemj5oEEtEPDdu02jeQ2jJorLJcwXccL1T4fvetDfcQab7lvG5GtatUCzbeK%2FrdRn%2F1s2VB5eQJ9i8QEtoeK4plqqnqYeEC9WboA7Yazh40BWsS4OhTS9FGMRxaEcNCD6pnaabRtyvU08Aa1DdP4MiO5WiL1Yy91Sk%2Bk92OvFy94axTLKrWtizRjozggmGYaiIp5GaiZmG%2FTiWbkHIuVH0UArqftSdxZcY6VtsO3AXiSVVj7OKltWjiTjspFepq%2FwoA%2BQjuaafVwd75xutekUxOnt%2FHicJ6DI8NlvNgufZ0Hm0nwVhCr6aIcQzvExjb2Q%2BpXxWE24UMziyAPVenVgcuRQnH474raRZa%2BSJsfkGT3jU6%2FNTV7b3UFgg4x3DKPRdK6K9CaFGDwRiK9vjuyjjFlUQYBvuhIXoPmpiCEpr5F5cJxgxu%2BCwSrEqJJGjSXiHn1Gvfp4kilqe4aRTPlA%2FZbsWnZWcpAwtKJo5LVCeqgCstOHTFW5OYQI4TOUviymwFxUeyD8SQ%2FXPtbYeaLDS8RmNaXehZUX8bEP3bzVT2vZNg7CioVVVMlnu8TmKnIaFn7%2FN19shgUVqLyO2zEF%2FzD97rtu7lH71PK5XMRY5ZwjuLouVU6E2rgfJqcV5Lz3tQhu%2Fug3jZKFVx9PK2TM6ayaT%2BiHb0EvYdzKpxRoMKmL68AGOrEBmUBVG9o8wf8Ltc9%2FwSqETfyeti5MLdPRvJkBSUq%2BwNTn9qD4d12VawVk1pZ4bvZIBksqSsAzup9gN0WAwW9Kd34r1ogP0IMc6xAd2Lnxl02uN%2BHV9f3S7cvXuVDPCiw32pfYmpMzEDBYoHTVBJhSzB52ZP7pqCsr0%2B0YJIAb9wRSan9etwQVUZ9xjslqAE8rzJDGl8qbqt5%2FS4nsBg8hz4G86uTEL51gTlSTKOJEllWK&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250507T032832Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYYR5MCS4T%2F20250507%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=8835660e7e2be15875f80cd6580542d3bc576670b9ebebc9752dda94c46046bc&hash=8750b34d59874e07e38abc4975b6bd9f7400c4a49b2e441561f96a59c251e1b4&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0164121209000405&tid=spdf-f89ff3a3-3030-4d14-bf6a-589a169e88f9&sid=222b408e94e0f144183b6c261406d23dd517gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=10165754030407560c5752&rr=93bda0b71a1ef6fe&cc=jp&kca=eyJrZXkiOiJUVjQ4ZlNYNktBYm9ldkZiV0I0NGRQUXVOeDZveFdDWTdUMktleE1DMEMyeW1SenBMNlYwc21FWURGaGJjYkdQOVZxdFRYMm1MZEpabEhDQkJwNytTeUlLdG0wRmRpdjNBbUdSSjJjMVV3V2lVVllsVTJWbEN6VURrVzdvVTNZNlZLWjM1SjNaVTlJNHhRbHp4SzVqbjVZaEV5QVBoQXVJQnhlSU81NUU3RlM2QlRNNSIsIml2IjoiNTdhMjUzYjg3NmRiNzIzNGFiZWFlYmU1ZWI5ZWYzZTEifQ==_1746588540980},
  year = {2009}
}
@article{A Survey on Adaptive Random Testing,
  abstract = { Random testing and partition testing are two major families of software testing techniques. They have been compared both theoretically and empirically in numerous studies for decades, and it has been widely acknowledged that they have their own advantages and disadvantages and that their innate characteristics are fairly complementary to each other. Some work has been conducted to develop advanced testing techniques through the integration of random testing and partition testing, attempting to preserve the advantages of both while minimizing their disadvantages. In this paper, we propose a new testing approach, adaptive partition testing, where test cases are randomly selected from some partition whose probability of being selected is adaptively adjusted along the testing process. We particularly develop two algorithms, Markov-chain based adaptive partition testing and reward-punishment based adaptive partition testing, to implement the proposed approach. The former algorithm makes use of Markov matrix to dynamically adjust the probability of a partition to be selected for conducting tests; while the latter is based on a reward and punishment mechanism. We conduct empirical studies to evaluate the performance of the proposed algorithms using ten faulty versions of three large-scale open source programs. Our experimental results show that, compared with two baseline techniques, namely random partition testing (RPT) and dynamic random testing (DRT), our algorithms deliver higher fault-detection effectiveness with lower test case selection overhead. It is demonstrated that the proposed adaptive partition testing is an effective testing approach, taking advantages of both random testing and partition testing.},
  author = {Rubing Huang, Weifeng Sun, Yinyin Xu, Haibo Chen, Dave Towey, Xin Xia},
  doi = {10.1109/TSE.2019.2942921},
  journal = {IEEE Transactions on Software Engineering},
  keywords = {Subspace constraints,Testing,Libraries,Software,Power capacitors,Strips,Art},
  number = {03},
  publisher = {IEEE},
  volume = {47},
  series = {Foundational Theories and Core Mechanisms},
  title = {A Survey on Adaptive Random Testing},
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8846002},
  year = {2019}
}
@article{ARTDL: Adaptive Random Testing for Deep Learning Systems,
  abstract = {With recent breakthroughs in Deep Learning (DL), DL systems are increasingly deployed in safety-critical fields. Hence, some software testing methods are required to ensure the reliability and safety of DL systems. Since the rules of DL systems are inferred from training data, it is difficult to know the implementation rules about each behavior of DL systems. At the same time, Random Testing (RT) is a popular testing method and the knowledge about software implementation is not needed when we use RT. Therefore, RT is very suitable for the testing of DL systems. And the existing mechanisms for testing DL systems also depend heavily on RT by the labeled test data. In order to increase the effectiveness of RT for DL systems, we design, implement and evaluate the Adaptive Random Testing for DL systems (ARTDL), which is the first Adaptive Random Testing (ART) method to improve the effectiveness of RT for DL systems. ARTDL refers to the idea of ART. That is, fewer test cases are needed to detect failures by selecting the test case with the furthest distance from non-failure-causing test cases. Firstly, we propose the Feature-based Euclidean Distance (FED) as the distance metric that can be used to measure the difference between failure-causing inputs and non-failure-causing inputs. Secondly, we verify the availability of FED by presenting the failure pattern of DL models. Finally, we design ARTDL algorithm to generate the test cases that are more likely to cause failures based on the FED. We implement ARTDL to test top performing DL models in the field of image classification and automatic driving. The results show that, on average, the number of test cases used to find the first bug is reduced by 62.74% through ARTDL, compared with RT.}
  author = {Min Yan, Li Wang, Aiguo Fei},
  doi = {10.1109/ACCESS.2019.2962695},
  journal = {IEEE Access},
  keywords = {Subspace constraints,Feature extraction,Measurement,Software,Deep learning,Software testing},
  number = {04},
  publisher = {IEEE},
  volume = {08},
  series = {ART in Complex and Intelligent Systems},
  title = {ARTDL: Adaptive Random Testing for Deep Learning Systems},
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8944083},
  year = {2019}
}
@article{Efficient and Unbiased Safety Test for Autonomous Driving Systems,
  abstract = {Test the safety of Autonomous Driving Systems (ADS) with realistic traffic conditions is important to the insurance industry, legislators, and third-party technical services. However, the scarcity of risky driving events distributed in real-world driving often makes sampling inefficient. In this paper, we propose a unified and hierarchical testing framework for efficient and unbiased safety tests of ADS. We first extract the risk subspace from the Naturalistic Driving Data (NDD) with defined safety measures. Subsequently, we use the Gaussian Copula method to accurately model the subspace joint probability density function (PDF). We further formulate a Kriging model-based optimization problem for finding the appropriate Importance Sampling (IS) parameters, where the Kriging model is trained iteratively within limited computational resources. Eventually, the risky concrete scenarios library is generated using the obtained Importance Sampling parameters. With the simulation results skewered back to the original risk subspace, the ADS probability of failure (e.g., crash rate) can thus be accurately and unbiasedly estimated. Experiment results show that using 0.94% computational resources, the Kriging surrogate model captures 96.04% of ADS crashes with at least 90.25% precision. On crash rate estimation, our proposed method achieves a consistent result with that of Monte Carlo simulation, provided that the relative error does not exceed 10% while improving the testing efficiency by up to 6,539 times.}
  author = {Zhengmin Jiang, Wenbo Pan, Jia Liu, Shaobo Dang, Zhiheng Yang, Huiyun Li},
  doi = {10.1109/TIV.2022.3213310},
  journal = {IEEE Transactions on Intelligent Vehicles},
  keywords = {Safety,Monte Carlo methods,Probability density function,Accidents,Testing,Computational modeling,Autonomous vehicles},
  number = {05},
  publisher = {IEEE},
  volume = {08},
  series = {ART in Complex and Intelligent Systems},
  title = {ARTDL: Adaptive Random Testing for Deep Learning Systems},
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9915421},
  year = {2022}
}
@article{Efficient and Unbiased Safety Test for Autonomous Driving Systems,
  abstract = {Mobile applications are becoming more and more powerful yet also more complex. While mobile application users expect the application to be reliable and secure, the complexity of the mobile application makes it prone to have faults. Mobile application engineers and testers use testing technique to ensure the quality of mobile application. However, the testing of mobile application is time-consuming and hard to automate. In this paper, we model the mobile application from a black box view and propose a distance metric for the test cases of mobile software. We further proposed an ART test case generation technique for mobile application. Our experiment shows our ART tool can both reduce the number of test cases and the time needed to expose first fault when compared with random technique.}
  author = {Zhifang Liu, Xiaopeng Gao, Xiang Long},
  doi = {10.1109/ICCET.2010.5485442},
  journal = {2010 2nd International Conference on Computer Engineering and Technology},
  keywords = {Application software,Reliability engineering,Software testing,Power engineering and energy,Mobile computing,Subspace constraints,Pervasive computing,Internet,Performance analysis,System testing},
  number = {06},
  publisher = {IEEE},
  volume = {01},
  series = {ART in Complex and Intelligent Systems},
  title = {Efficient and Unbiased Safety Test for Autonomous Driving Systems},
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5485442},
  year = {2010}
}
@article{A novel evolutionary approach for adaptive random testing,
  abstract = {Random testing is a low cost strategy that can be applied to a wide range of testing problems. While the cost and straightforward application of random testing are appealing, these benefits must be evaluated against the reduced effectiveness due to the generality of the approach. Recently, a number of novel techniques, coined Adaptive Random Testing, have sought to increase the effectiveness of random testing by attempting to maximize the testing coverage of the input domain. This paper presents the novel application of an evolutionary search algorithm to this problem. The results of an extensive simulation study are presented in which the evolutionary approach is compared against the Fixed Size Candidate Set (FSCS), Restricted Random Testing (RRT), quasi-random testing using the Sobol sequence (Sobol), and random testing (RT) methods. The evolutionary approach was found to be superior to FSCS, RRT, Sobol, and RT amongst block patterns, the arena in which FSCS, and RRT have demonstrated the most appreciable gains in testing effectiveness. The results among fault patterns with increased complexity were shown to be similar to those of FSCS, and RRT; and showed a modest improvement over Sobol, and RT. A comparison of the asymptotic and empirical runtimes of the evolutionary search algorithm, and the other testing approaches, was also considered, providing further evidence that the application of an evolutionary search algorithm is feasible, and within the same order of time complexity as the other adaptive random testing approaches.}
  author = {Andrew F. Tappenden, James Miller},
  doi = {10.1109/TR.2009.2034288},
  journal = {IEEE Transactions on Reliability},
  keywords = {Biological cells,Automatic testing,Software testing,Power capacitors,Costs,Genetic algorithms,Analysis of variance,Subspace constraints,Runtime,Application software},
  number = {07},
  publisher = {IEEE},
  volume = {58},
  series = {ART Hybridization and Evolution},
  title = {A novel evolutionary approach for adaptive random testing},
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5338642},
  year = {2009}
}
@article{Adaptive stress testing for autonomous vehicles,
  abstract = {This paper presents a method for testing the decision making systems of autonomous vehicles. Our approach involves perturbing stochastic elements in the vehicle's environment until the vehicle is involved in a collision. Instead of applying direct Monte Carlo sampling to find collision scenarios, we formulate the problem as a Markov decision process and use reinforcement learning algorithms to find the most likely failure scenarios. This paper presents Monte Carlo Tree Search (MCTS) and Deep Reinforcement Learning (DRL) solutions that can scale to large environments. We show that DRL can find more likely failure scenarios than MCTS with fewer calls to the simulator. A simulation scenario involving a vehicle approaching a crosswalk is used to validate the framework. Our proposed approach is very general and can be easily applied to other scenarios given the appropriate models of the vehicle and the environment.}
  author = {Mark Koren, Saud Alsaif, Ritchie Lee, Mykel J. Kochenderfer},
  doi = {10.1109/IVS.2018.8500400},
  journal = {2018 IEEE Intelligent Vehicles Symposium (IV)},
  keywords = {Autonomous vehicles,Sensors,Testing,Markov processes,Roads,Stress,Monte Carlo methods},
  number = {08},
  publisher = {IEEE},
  volume = {01},
  series = {ART Hybridization and Evolution},
  title = {Adaptive stress testing for autonomous vehicles},
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8500400},
  year = {2018}
}
@article{Accelerated Testing and Evaluation for Black-Box Autonomous Driving Systems via Adaptive Markov Chain Monte Carlo,
  abstract = {This paper presents a method for testing the decision making systems of autonomous vehicles. Our approach involves perturbing stochastic elements in the vehicle's environment until the vehicle is involved in a collision. Instead of applying direct Monte Carlo sampling to find collision scenarios, we formulate the problem as a Markov decision process and use reinforcement learning algorithms to find the most likely failure scenarios. This paper presents Monte Carlo Tree Search (MCTS) and Deep Reinforcement Learning (DRL) solutions that can scale to large environments. We show that DRL can find more likely failure scenarios than MCTS with fewer calls to the simulator. A simulation scenario involving a vehicle approaching a crosswalk is used to validate the framework. Our proposed approach is very general and can be easily applied to other scenarios given the appropriate models of the vehicle and the environment.}
  author = {Yuxiong Ji, Zhongke Xu, Cong Zhao, Kun Chen, Yuchuan Du},
  doi = {10.1109/TITS.2024.3525059},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  keywords = {Decision making,Autonomous vehicles,Closed box,Safety,Testing,Training,Monte Carlo methods,Estimation,Life estimation,Predictive models},
  number = {09},
  publisher = {IEEE},
  volume = {26},
  series = {ART Hybridization and Evolution},
  title = {Accelerated Testing and Evaluation for Black-Box Autonomous Driving Systems via Adaptive Markov Chain Monte Carlo},
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10843161},
  year = {2024}
}
@article{A Survey on Metamorphic Testing,
  abstract = {A test oracle determines whether a test execution reveals a fault, often by comparing the observed program output to the expected output. This is not always practical, for example when a program's input-output relation is complex and difficult to capture formally. Metamorphic testing provides an alternative, where correctness is not determined by checking an individual concrete output, but by applying a transformation to a test input and observing how the program output “morphs” into a different one as a result. Since the introduction of such metamorphic relations in 1998, many contributions on metamorphic testing have been made, and the technique has seen successful applications in a variety of domains, ranging from web services to computer graphics. This article provides a comprehensive survey on metamorphic testing: It summarises the research results and application areas, and analyses common practice in empirical studies of metamorphic testing as well as the main open challenges.}
  author = {Sergio Segura, Gordon Fraser, Ana B. Sanchez, Antonio Ruiz-Cortés},
  doi = {10.1109/TSE.2016.2532875},
  journal = {IEEE Transactions on Software Engineering},
  keywords = {Testing,Search engines,Google,Libraries,Concrete,Distance measurement,Web services},
  number = {10},
  publisher = {IEEE},
  volume = {42},
  series = {ART and Testing Paradigm Extensions},
  title = {A Survey on Metamorphic Testing},
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7422146},
  year = {2016}
}